#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ FastAPI æœåŠ¡ï¼šè¯´è¯äººæ—¥å¿— â†’ ASR â†’ æ ‡ç‚¹ â†’ è§’è‰²æ˜ å°„ï¼ˆåŒ»ç”Ÿ/é¡¾å®¢ï¼‰
åŒæ—¶æ”¯æŒï¼š
  - /transcribe: è§’è‰²åˆ†ç¦»ï¼ˆéœ€ä¸»éŸ³é¢‘ + åŒ»ç”Ÿæ³¨å†ŒéŸ³é¢‘ï¼‰
  - /asr: éæµå¼ ASR + çƒ­è¯ï¼ˆå•éŸ³é¢‘ï¼‰
  - /ws/asr: æ»‘åŠ¨çª—å£ WebSocket ASR + çƒ­è¯ï¼ˆå®æ—¶ï¼‰
"""

import os
import json
import tempfile
import time
import torch
import numpy as np
import logging
import asyncio
import io
import traceback
import uuid
from pathlib import Path
from typing import Dict, Any

from fastapi import FastAPI, File, UploadFile, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse
from pydub import AudioSegment
from funasr import AutoModel
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
import soundfile

# ==============================
# ğŸ”§ æ—¥å¿— & é…ç½®
# ==============================
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger("ASRService")
# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path("./outputs")
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

# è®¾å¤‡
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
SIMILARITY_THRESHOLD = 0.7

# æ¨¡å‹è·¯å¾„ï¼ˆæ”¯æŒçƒ­è¯çš„ Paraformerï¼‰
VAD_MODEL_PATH = "/home/dieu/.cache/modelscope/hub/models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch"
SD_MODEL_PATH = "/home/dieu/.cache/modelscope/hub/models/damo/speech_campplus_speaker-diarization_common"
ASR_MODEL_PATH = "iic/speech_paraformer-large-contextual_asr_nat-zh-cn-16k-common-vocab8404"  # æ”¯æŒ hotword
PUNC_MODEL_PATH = "iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch"
XVECTOR_MODEL_PATH = "iic/speech_campplus_sv_zh-cn_16k-common"

# å…¨å±€æ¨¡å‹ & çƒ­è¯
vad_model = None
sd_model = None
asr_model = None
punc_model = None
xvector_model = None
global_hotword_str = ""

app = FastAPI(title="Speaker Diarization + ASR + Hotword Service", version="1.0")

# ==============================
# ğŸ§° å·¥å…·å‡½æ•°
# ==============================
def load_hotwords(file_path: str = "hotwords.txt") -> str:
    """ä»æ–‡æœ¬æ–‡ä»¶åŠ è½½çƒ­è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œè¿”å›ç©ºæ ¼æ‹¼æ¥çš„å­—ç¬¦ä¸²"""
    if not os.path.exists(file_path):
        logger.warning(f"Hotword file {file_path} not found. Using empty hotword.")
        return ""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            hotwords = [line.strip() for line in f if line.strip()]
        hotword_str = " ".join(hotwords)
        logger.info(f"Loaded {len(hotwords)} hotwords from {file_path}.")
        return hotword_str
    except Exception as e:
        logger.error(f"Failed to load hotwords from {file_path}: {e}")
        return ""

def check_keywords(text: str):
    keywords = ["ç´§æ€¥", "æŠ¥è­¦", "å±é™©"]
    for kw in keywords:
        if kw in text:
            logger.warning(f"âš ï¸ Keyword detected: '{kw}' in text: '{text}'")

def get_embedding(audio_path):
    result = xvector_model.generate(input=audio_path)
    if result and isinstance(result[0], dict):
        emb = result[0].get("spk_embedding")
        if emb is not None:
            if isinstance(emb, torch.Tensor):
                emb = emb.cpu().numpy()
            return emb.flatten()
    raise ValueError(f"æ— æ³•æå– embedding: {audio_path}")

def format_time(seconds: float) -> str:
    if seconds < 0:
        seconds = 0.0
    ms = int(round(seconds * 1000))
    h, m, s = ms // 3600000, (ms % 3600000) // 60000, (ms % 60000) // 1000
    return f"{h:02d}:{m:02d}:{s:02d}.{ms % 1000:03d}"

def save_upload_file(upload_file: UploadFile, suffix: str = ".wav") -> str:
    try:
        contents = upload_file.file.read()
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(contents)
            return tmp.name
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¿å­˜ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
    finally:
        upload_file.file.close()

# ==============================
# ğŸš€ å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
# ==============================
@app.on_event("startup")
def load_models():
    global vad_model, sd_model, asr_model, punc_model, xvector_model, global_hotword_str
    logger.info("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    global_hotword_str = load_hotwords("hotwords.txt")

    try:
        vad_model = AutoModel(
            model=VAD_MODEL_PATH,
            model_revision="v2.0.4",
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        sd_model = pipeline(
            task='speaker-diarization',
            model=SD_MODEL_PATH,
            model_revision="v1.0.0",
            vad_model=VAD_MODEL_PATH,
            vad_model_revision="v2.0.4",
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        asr_model = pipeline(
            task=Tasks.auto_speech_recognition,
            model=ASR_MODEL_PATH,
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        punc_model = AutoModel(
            model=PUNC_MODEL_PATH,
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        xvector_model = AutoModel(
            model=XVECTOR_MODEL_PATH,
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        logger.info("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise

# ==============================
# ğŸŒ API æ¥å£
# ==============================

@app.post("/transcribe")
async def transcribe_audio(
    audio: UploadFile = File(..., description="ä¸»å¯¹è¯éŸ³é¢‘æ–‡ä»¶ (WAV/MP3ç­‰)"),
    doctor_enroll: UploadFile = File(..., description="åŒ»ç”Ÿæ³¨å†ŒéŸ³é¢‘æ–‡ä»¶ (16kHz, mono)")
):
    start_time = time.time()
    main_audio_path = None
    doctor_audio_path = None
    full_audio = None

    try:
        main_audio_path = save_upload_file(audio)
        doctor_audio_path = save_upload_file(doctor_enroll)

        full_audio = AudioSegment.from_file(main_audio_path).set_frame_rate(16000).set_channels(1)

        # è¯´è¯äººæ—¥å¿—
        sd_result = sd_model(main_audio_path)
        raw_segments = sd_result.get("text", [])
        if not raw_segments:
            raise HTTPException(status_code=400, detail="æœªæ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³ç‰‡æ®µ")

        # æå–æ¯ä¸ªè¯´è¯äºº embeddingï¼ˆä½¿ç”¨ç¬¬ä¸€æ®µï¼‰
        spk_to_embedding = {}
        spk_to_segments = {}

        for start_sec, end_sec, spk_id in raw_segments:
            spk_key = f"spk{spk_id}"
            if spk_key not in spk_to_segments:
                spk_to_segments[spk_key] = []
            spk_to_segments[spk_key].append((start_sec, end_sec))

        for spk_key, seg_list in spk_to_segments.items():
            start_sec, end_sec = seg_list[0]
            start_ms = int(start_sec * 1000)
            end_ms = int(end_sec * 1000)
            seg_audio = full_audio[start_ms:end_ms]
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                seg_path = f.name
                seg_audio.export(seg_path, format="wav")
            try:
                emb = get_embedding(seg_path)
                spk_to_embedding[spk_key] = emb
            finally:
                os.unlink(seg_path)

        # åŒ¹é…åŒ»ç”Ÿ
        doctor_emb = get_embedding(doctor_audio_path)
        doctor_spk = None
        best_sim = -1.0
        for spk_key, emb in spk_to_embedding.items():
            sim = float(np.dot(doctor_emb, emb))
            if sim >= SIMILARITY_THRESHOLD and sim > best_sim:
                best_sim = sim
                doctor_spk = spk_key

        if doctor_spk is None:
            doctor_spk = list(spk_to_embedding.keys())[0] if spk_to_embedding else "spk0"

        # ASR + æ ‡ç‚¹ + æ„å»ºç»“æœ
        final_segments = []
        for start_sec, end_sec, spk_id in raw_segments:
            spk_key = f"spk{spk_id}"
            role = 0 if spk_key == doctor_spk else 1

            start_ms = int(start_sec * 1000)
            end_ms = int(end_sec * 1000)
            seg_audio = full_audio[start_ms:end_ms]

            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                seg_path = f.name
                seg_audio.export(seg_path, format="wav")

            try:
                asr_res = asr_model(seg_path, hotword=global_hotword_str)
                text = ""
                if isinstance(asr_res, list) and len(asr_res) > 0:
                    text = asr_res[0].get("text", "").strip()
                elif isinstance(asr_res, dict):
                    text = asr_res.get("text", "").strip()

                if text:
                    punc_res = punc_model.generate(input=text)
                    text = punc_res[0].get("text", text) if punc_res else text

                if text:
                    speaker_label = "doctor" if role == 0 else "customer"
                    final_segments.append({
                        "time": format_time(start_sec),
                        "endTime": format_time(end_sec),
                        "role": speaker_label,
                        "content": text
                    })
            finally:
                os.unlink(seg_path)

        total_time = time.time() - start_time
        result = {
            "status": "success",
            "processing_time_seconds": round(total_time, 2),
            "segments": final_segments
        }

        output_filename = f"transcript_{uuid.uuid4().hex[:8]}_{int(time.time())}.json"
        output_json_path = OUTPUT_DIR / output_filename
        with open(output_json_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        return JSONResponse(content=result)

    except Exception as e:
        error_detail = f"å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        logger.error(error_detail)
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        for path in [main_audio_path, doctor_audio_path]:
            if path and os.path.exists(path):
                os.unlink(path)

@app.post("/asr")
async def asr_with_hotwords(audio: UploadFile = File(..., description="éŸ³é¢‘æ–‡ä»¶ (WAV/MP3ç­‰)")):
    """
    éæµå¼ ASR æ¥å£ï¼Œæ”¯æŒçƒ­è¯å¢å¼º
    """
    temp_path = None
    try:
        temp_path = save_upload_file(audio)

        result = asr_model(temp_path, hotword=global_hotword_str)
        text = ""
        if isinstance(result, list) and len(result) > 0:
            text = result[0].get("text", "").strip()
        elif isinstance(result, dict):
            text = result.get("text", "").strip()

        # å¯é€‰ï¼šåŠ æ ‡ç‚¹
        if text and punc_model:
            punc_res = punc_model.generate(input=text)
            text = punc_res[0].get("text", text) if punc_res else text

        return JSONResponse(content={
            "status": "success",
            "text": text,
            "hotwords_used": global_hotword_str
        })

    except Exception as e:
        logger.error(f"ASR å¤„ç†å¤±è´¥: {e}\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if temp_path and os.path.exists(temp_path):
            os.unlink(temp_path)

@app.websocket("/ws/asr")
async def websocket_asr(websocket: WebSocket):
    await websocket.accept()
    logger.info("WebSocket client connected.")

    sample_rate = 16000
    audio_buffer = np.array([], dtype=np.float32)

    WINDOW_DURATION = 3.0
    STEP_DURATION = 1.0

    window_samples = int(WINDOW_DURATION * sample_rate)
    step_samples = int(STEP_DURATION * sample_rate)
    total_processed_samples = 0

    try:
        while True:
            data = await websocket.receive()

            if "bytes" in data:
                audio_bytes = data["bytes"]
                try:
                    wav_io = io.BytesIO(audio_bytes)
                    audio_chunk, sr = soundfile.read(wav_io, dtype='float32')

                    if sr != sample_rate:
                        await websocket.send_text(json.dumps({
                            "error": f"Unsupported sample rate: {sr}Hz. Expected {sample_rate}Hz."
                        }))
                        continue

                    if audio_chunk.ndim > 1:
                        audio_chunk = audio_chunk[:, 0]

                    audio_buffer = np.concatenate([audio_buffer, audio_chunk])

                    while len(audio_buffer) >= window_samples:
                        window_audio = audio_buffer[:window_samples]
                        seg_start = total_processed_samples / sample_rate
                        seg_end = (total_processed_samples + window_samples) / sample_rate

                        loop = asyncio.get_event_loop()
                        try:
                            res = await loop.run_in_executor(
                                None,
                                lambda: asr_model(window_audio, hotword=global_hotword_str)
                            )
                            text = ""
                            if isinstance(res, list) and len(res) > 0:
                                text = res[0].get("text", "")
                            elif isinstance(res, dict):
                                text = res.get("text", "")
                            text = text.strip()

                            await websocket.send_text(json.dumps({
                                "corrected": text,
                                "segment_start": round(seg_start, 2),
                                "segment_end": round(seg_end, 2)
                            }))

                            if text:
                                check_keywords(text)

                        except Exception as e:
                            logger.error(f"ASR recognition failed: {e}")
                            await websocket.send_text(json.dumps({"error": "ASR recognition failed"}))

                        audio_buffer = audio_buffer[step_samples:]
                        total_processed_samples += step_samples

                except Exception as e:
                    logger.error(f"Error processing audio chunk: {e}")
                    await websocket.send_text(json.dumps({"error": "Audio processing failed"}))

            elif "text" in data:
                try:
                    msg = json.loads(data["text"])
                    if msg.get("is_final"):
                        final_text = ""
                        if len(audio_buffer) > 0:
                            loop = asyncio.get_event_loop()
                            try:
                                res = await loop.run_in_executor(
                                    None,
                                    lambda: asr_model(audio_buffer, hotword=global_hotword_str)
                                )
                                if isinstance(res, list) and len(res) > 0:
                                    final_text = res[0].get("text", "")
                                elif isinstance(res, dict):
                                    final_text = res.get("text", "")
                                final_text = final_text.strip()
                            except Exception as e:
                                logger.error(f"Final ASR failed: {e}")

                        await websocket.send_text(json.dumps({
                            "final": final_text,
                            "corrected_final": final_text
                        }))
                        break

                except json.JSONDecodeError:
                    await websocket.send_text(json.dumps({"error": "Invalid JSON"}))

    except WebSocketDisconnect:
        logger.info("WebSocket client disconnected.")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        await websocket.close()

@app.get("/")
def read_root():
    return {
        "message": "æ¬¢è¿ä½¿ç”¨è¯´è¯äººæ—¥å¿— + ASR + çƒ­è¯æœåŠ¡ï¼",
        "endpoints": {
            "è§’è‰²åˆ†ç¦»": "POST /transcribe (audio + doctor_enroll)",
            "éæµå¼ASR": "POST /asr (audio)",
            "æµå¼ASR": "WebSocket /ws/asr"
        }
    }

# ==============================
# ğŸ å¯åŠ¨å…¥å£
# ==============================
if __name__ == "__main__":
    import uvicorn
    logger.info("Starting ASR server on http://0.0.0.0:8001")
    uvicorn.run(app, host="0.0.0.0", port=8001)
