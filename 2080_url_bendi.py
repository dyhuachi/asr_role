#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ FastAPI æœåŠ¡ï¼šè¯´è¯äººæ—¥å¿— â†’ ASR â†’ æ ‡ç‚¹ â†’ è§’è‰²æ˜ å°„ï¼ˆåŒ»ç”Ÿ/é¡¾å®¢ï¼‰
âœ… æ”¯æŒä¸¤ç§è°ƒç”¨æ–¹å¼ï¼š
  1. ä¸Šä¼ æ–‡ä»¶ï¼ˆmultipart/form-dataï¼‰ â†’ ç”¨äºæœ¬åœ°æµ‹è¯•
     - /transcribe: audio + doctor_enroll (File)
     - /asr: audio (File)
  2. ä¼ å…¥ URLï¼ˆapplication/jsonï¼‰ â†’ ç”¨äºç”Ÿäº§
     - /transcribe: { "audio_url": "...", "doctor_enroll_url": "..." }
     - /asr: { "audio_url": "..." }
"""
import uuid
import os
import json
import tempfile
import time
import torch
import numpy as np
import logging
from pathlib import Path
from typing import Optional
from pydantic import BaseModel

import httpx
from urllib.parse import urlparse

from fastapi import FastAPI, File, UploadFile, HTTPException, Request
from fastapi.responses import JSONResponse
from pydub import AudioSegment
from funasr import AutoModel
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

# ==============================
# ğŸ”§ æ—¥å¿— & é…ç½®
# ==============================
# åˆ é™¤åŸæ¥çš„ logging.basicConfig å’Œ setLevel
logger = logging.getLogger("ASRService")

# å¼ºåˆ¶è®¾ç½® logger çº§åˆ«
logger.setLevel(logging.INFO)

# é˜²æ­¢æ—¥å¿—ä¼ é€’ç»™ root loggerï¼ˆé¿å…è¢« root çš„ WARNING çº§åˆ«è¿‡æ»¤ï¼‰
logger.propagate = False

# å¦‚æœè¿˜æ²¡æœ‰ handlerï¼Œæ‰‹åŠ¨æ·»åŠ ä¸€ä¸ªï¼ˆç¡®ä¿è¾“å‡ºåˆ°æ§åˆ¶å°ï¼‰
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    handler.setFormatter(formatter)
    logger.addHandler(handler)
OUTPUT_DIR = Path("./outputs")
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

# --- æ¨¡å‹ç¼“å­˜ç›®å½• ---
os.environ["MODELSCOPE_CACHE"] = "./"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
SIMILARITY_THRESHOLD = 0.7

# æ¨¡å‹è·¯å¾„
VAD_MODEL_PATH = "./models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch"
SD_MODEL_PATH = "./models/damo/speech_campplus_speaker-diarization_common"
ASR_MODEL_PATH = "./models/iic/speech_paraformer-large-contextual_asr_nat-zh-cn-16k-common-vocab8404"
PUNC_MODEL_PATH = "./models/iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch"
XVECTOR_MODEL_PATH = "./models/iic/speech_campplus_sv_zh-cn_16k-common"

# å…¨å±€æ¨¡å‹ & çƒ­è¯
vad_model = None
sd_model = None
asr_model = None
punc_model = None
xvector_model = None
global_hotword_str = ""

app = FastAPI(title="Speaker Diarization + ASR + Hotword Service", version="2.0 (Upload + URL)")
# from starlette.exceptions import HTTPException as StarletteHTTPException
#
# @app.exception_handler(StarletteHTTPException)
# async def http_exception_handler(request: Request, exc: StarletteHTTPException):
#     return JSONResponse(
#         status_code=exc.status_code,
#         content={"code": 0, "detail": exc.detail}
#     )
# ==============================
# ğŸ“¥ æ•°æ®æ¨¡å‹ï¼ˆä»…ç”¨äº URLï¼‰
# ==============================
class ASRURLRequest(BaseModel):
    audio_url: str

class TranscribeURLRequest(BaseModel):
    audio_url: str
    doctor_enroll_url: str

# ==============================
# ğŸ§° å·¥å…·å‡½æ•°
# ==============================
def load_hotwords(file_path: str = "hotwords.txt") -> str:
    if not os.path.exists(file_path):
        logger.warning(f"Hotword file {file_path} not found. Using empty hotword.")
        return ""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            hotwords = [line.strip() for line in f if line.strip()]
        hotword_str = " ".join(hotwords)
        logger.info(f"Loaded {len(hotwords)} hotwords from {file_path}.")
        return hotword_str
    except Exception as e:
        logger.error(f"Failed to load hotwords from {file_path}: {e}")
        return ""

def download_audio_from_url(url: str) -> str:
    try:
        parsed = urlparse(url)
        if not parsed.scheme or not parsed.netloc:
            raise ValueError("Invalid URL")

        with httpx.Client(timeout=21600.0) as client:
            response = client.get(url)
            response.raise_for_status()

        content_type = response.headers.get("content-type", "").lower()
        suffix = ".wav"
        if "mpeg" in content_type or url.endswith(".mp3"):
            suffix = ".mp3"
        elif "wav" in content_type or url.endswith(".wav"):
            suffix = ".wav"

        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(response.content)
            logger.info(f"Downloaded: {url} â†’ {tmp.name}")
            return tmp.name
    except Exception as e:
        logger.error(f"Download failed: {url} | {e}")
        raise HTTPException(status_code=400, detail=f"Failed to download audio from URL: {str(e)}")

def save_upload_file(upload_file: UploadFile, suffix: str = ".wav") -> str:
    try:
        contents = upload_file.file.read()
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(contents)
            return tmp.name
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¿å­˜ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
    finally:
        upload_file.file.close()

def get_embedding(audio_path):
    result = xvector_model.generate(input=audio_path)
    if result and isinstance(result[0], dict):
        emb = result[0].get("spk_embedding")
        if emb is not None:
            if isinstance(emb, torch.Tensor):
                emb = emb.cpu().numpy()
            return emb.flatten()
    raise ValueError(f"æ— æ³•æå– embedding: {audio_path}")

def format_time(seconds: float) -> str:
    if seconds < 0:
        seconds = 0.0
    ms = int(round(seconds * 1000))
    h, m, s = ms // 3600000, (ms % 3600000) // 60000, (ms % 60000) // 1000
    return f"{h:02d}:{m:02d}:{s:02d}.{ms % 1000:03d}"

# ==============================
# ğŸš€ å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
# ==============================
@app.on_event("startup")
def load_models():
    global vad_model, sd_model, asr_model, punc_model, xvector_model, global_hotword_str
    logger.info("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    global_hotword_str = load_hotwords("hotwords.txt")

    try:
        vad_model = AutoModel(
            model=VAD_MODEL_PATH,
            # model_revision="v2.0.4",
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        # ä½¿ç”¨ pipeline åŠ è½½ VAD æ¨¡å‹
        # vad_model = pipeline(
        #     task="voice-activity-detection",
        #     model=VAD_MODEL_PATH,
        #     model_revision="v2.0.4",
        #     device=DEVICE,
        #     disable_update=True,
        #     update_model=False,
        # )
        sd_model = pipeline(
            task='speaker-diarization',
            model=SD_MODEL_PATH,
            # model_revision="v1.0.0",
            # vad_model=VAD_MODEL_PATH,
            # vad_model_revision="v2.0.4",
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        asr_model = pipeline(
            task=Tasks.auto_speech_recognition,
            model=ASR_MODEL_PATH,
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        punc_model = AutoModel(
            model=PUNC_MODEL_PATH,
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        xvector_model = AutoModel(
            model=XVECTOR_MODEL_PATH,
            disable_update=True,
            update_model=False,
            device=DEVICE
        )
        print(f"DEVICE:{DEVICE}")
        logger.info("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise
import os
import wave
from pydub import AudioSegment  # å¯é€‰ï¼Œç”¨äºæ›´è¯¦ç»†çš„éŸ³é¢‘åˆ†æ

def get_audio_duration(path: str) -> float:
    """è¿”å›éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œæ”¯æŒ WAVã€MP3 ç­‰å¸¸è§æ ¼å¼"""
    try:
        # å°è¯•ç”¨ pydubï¼ˆæ›´é€šç”¨ï¼‰
        audio = AudioSegment.from_file(path)
        return len(audio) / 1000.0  # æ¯«ç§’è½¬ç§’
    except Exception as e:
        logger.warning(f"æ— æ³•ç”¨ pydub è¯»å– {path}: {e}")
        # å›é€€åˆ° waveï¼ˆä»…é™ WAVï¼‰
        try:
            with wave.open(path, 'r') as wf:
                frames = wf.getnframes()
                rate = wf.getframerate()
                return frames / float(rate)
        except:
            return 0.0
# ==============================
# ğŸ”„ é€šç”¨å¤„ç†å‡½æ•°ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
# ==============================
def _process_asr(temp_audio_path: str) -> str:
    result = asr_model(temp_audio_path, hotword=global_hotword_str)
    text = ""
    if isinstance(result, list) and len(result) > 0:
        text = result[0].get("text", "").strip()
    elif isinstance(result, dict):
        text = result.get("text", "").strip()
    if text and punc_model:
        punc_res = punc_model.generate(input=text)
        text = punc_res[0].get("text", text) if punc_res else text
    return text

def _process_transcribe(main_path: str, doctor_path: str) -> dict:
    start_time = time.time()
    # ===== æ–°å¢ï¼šå•ç‹¬è¿è¡Œ VAD å¹¶æ‰“å°ç»“æœ =====
    logger.info(f"Running VAD on main audio: {main_path}")
    vad_result = vad_model.generate(input=main_path)
    logger.info(f"VAD result: {vad_result}")

    if not vad_result or not vad_result[0].get("value"):
        raise HTTPException(status_code=400, detail="VAD æœªæ£€æµ‹åˆ°ä»»ä½•æœ‰æ•ˆè¯­éŸ³æ®µï¼éŸ³é¢‘å¯èƒ½å…¨æ˜¯é™éŸ³ã€‚")

    vad_segments = vad_result[0]["value"]
    total_vad_duration = sum(seg[1] - seg[0] for seg in vad_segments)
    logger.info(f"VAD æ£€æµ‹åˆ° {len(vad_segments)} æ®µè¯­éŸ³ï¼Œæ€»æœ‰æ•ˆæ—¶é•¿: {total_vad_duration:.2f} ç§’")

    if total_vad_duration < 0.5:
        raise HTTPException(status_code=400, detail=f"æœ‰æ•ˆè¯­éŸ³æ—¶é•¿è¿‡çŸ­ ({total_vad_duration:.2f}s)ï¼Œè¯·æ£€æŸ¥å½•éŸ³è´¨é‡ã€‚")
    # =========================================
    full_audio = AudioSegment.from_file(main_path).set_frame_rate(16000).set_channels(1)

    def standardize_audio_for_modelscope(src_path: str) -> str:
        """è½¬æ¢ä¸º ModelScope å…¼å®¹çš„ 16kHz, å•å£°é“, 16-bit PCM WAV"""
        audio = AudioSegment.from_file(src_path)
        audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)
        dst_path = str(Path(src_path).with_suffix("")) + "_modelscope.wav"
        audio.export(dst_path, format="wav")
        os.unlink(src_path)  # æ¸…ç†åŸå§‹ä¸´æ—¶æ–‡ä»¶
        return dst_path
    main_path = standardize_audio_for_modelscope(main_path)
    # === 3. è°ƒç”¨ sd_model æ—¶ä¼ å…¥ segmentsï¼Œè·³è¿‡å†…éƒ¨ VADï¼===
    sd_result = sd_model(main_path,oracle_num=2)
    raw_segments = sd_result.get("text", [])
    logger.info(f"SD åˆ†æ®µ: {raw_segments}")
    if not raw_segments:
        raise HTTPException(status_code=400, detail="æœªæ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³ç‰‡æ®µ")

    spk_to_embedding = {}
    spk_to_segments = {}
    for start_sec, end_sec, spk_id in raw_segments:
        spk_key = f"spk{spk_id}"
        if spk_key not in spk_to_segments:
            spk_to_segments[spk_key] = []
        spk_to_segments[spk_key].append((start_sec, end_sec))

    for spk_key, seg_list in spk_to_segments.items():
        start_sec, end_sec = seg_list[0]
        start_ms = int(start_sec * 1000)
        end_ms = int(end_sec * 1000)
        seg_audio = full_audio[start_ms:end_ms]
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            seg_audio.export(f.name, format="wav")
            try:
                emb = get_embedding(f.name)
                spk_to_embedding[spk_key] = emb
            finally:
                os.unlink(f.name)

    doctor_emb = get_embedding(doctor_path)
    doctor_spk = None
    best_sim = -1.0
    for spk_key, emb in spk_to_embedding.items():
        sim = float(np.dot(doctor_emb, emb))
        if sim >= SIMILARITY_THRESHOLD and sim > best_sim:
            best_sim = sim
            doctor_spk = spk_key

    if doctor_spk is None:
        doctor_spk = list(spk_to_embedding.keys())[0] if spk_to_embedding else "spk0"

    final_segments = []
    for start_sec, end_sec, spk_id in raw_segments:
        spk_key = f"spk{spk_id}"
        role = 0 if spk_key == doctor_spk else 1
        start_ms = int(start_sec * 1000)
        end_ms = int(end_sec * 1000)
        seg_audio = full_audio[start_ms:end_ms]

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            seg_audio.export(f.name, format="wav")
            try:
                text = _process_asr(f.name)
                if text:
                    speaker_label = "doctor" if role == 0 else "customer"
                    final_segments.append({
                        "time": format_time(start_sec),
                        "endTime": format_time(end_sec),
                        "role": speaker_label,
                        "content": text
                    })
            finally:
                os.unlink(f.name)

    total_time = time.time() - start_time
    return {
        "status": "success",
        "processing_time_seconds": round(total_time, 2),
        "segments": final_segments
    }

# ==============================
# ğŸŒ API æ¥å£ï¼ˆå…¼å®¹ä¸Šä¼ å’Œ URLï¼‰
# ==============================

@app.post("/asr")
async def asr_with_hotwords(
    request: Request,
    audio: Optional[UploadFile] = File(None)
):
    temp_path = None
    try:
        content_type = request.headers.get("content-type", "")
        if "application/json" in content_type:
            body = await request.json()
            audio_url = body.get("audio_url")
            if not audio_url:
                raise HTTPException(status_code=400, detail="JSON body å¿…é¡»åŒ…å« audio_url")
            temp_path = download_audio_from_url(audio_url)
        elif audio is not None:
            temp_path = save_upload_file(audio)
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾› audio æ–‡ä»¶æˆ– JSON ä¸­çš„ audio_url")

        text = _process_asr(temp_path)
        return JSONResponse(content={
            "status": "success",
            "text": text,
            "hotwords_used": global_hotword_str
        })

    except Exception as e:
        logger.error(f"ASR å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if temp_path and os.path.exists(temp_path):
            os.unlink(temp_path)

@app.post("/transcribe")
async def transcribe_audio(
    request: Request,
    audio: Optional[UploadFile] = File(None),
    doctor_enroll: Optional[UploadFile] = File(None)
):
    logger.info("=== è¿›å…¥ transcribe æ¥å£ ===")  # çœ‹è¿™è¡Œæ˜¯å¦æ‰“å°
    main_path = doctor_path = None
    try:
        content_type = request.headers.get("content-type", "")
        if "application/json" in content_type:
            body = await request.json()
            audio_url = body.get("audio_url")
            doctor_url = body.get("doctor_enroll_url")
            if not audio_url or not doctor_url:
                raise HTTPException(status_code=400, detail="JSON body å¿…é¡»åŒ…å« audio_url å’Œ doctor_enroll_url")
            main_path = download_audio_from_url(audio_url)
            doctor_path = download_audio_from_url(doctor_url)
        elif audio is not None and doctor_enroll is not None:
            main_path = save_upload_file(audio)
            doctor_path = save_upload_file(doctor_enroll)
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»åŒæ—¶æä¾› audio + doctor_enroll æ–‡ä»¶ï¼Œæˆ– JSON ä¸­çš„ä¸¤ä¸ª URL")
        # åœ¨è°ƒç”¨ _process_transcribe ä¹‹å‰
        main_duration = get_audio_duration(main_path)
        doctor_duration = get_audio_duration(doctor_path)

        logger.info(f"Main audio duration: {main_duration:.2f}s, Doctor audio duration: {doctor_duration:.2f}s")

        if main_duration < 0.5:
            raise HTTPException(status_code=400,
                                detail=f"ä¸»éŸ³é¢‘æœ‰æ•ˆæ—¶é•¿è¿‡çŸ­ ({main_duration:.2f}s)ï¼Œè¯·æä¾›è‡³å°‘ 0.5 ç§’çš„è¯­éŸ³")
        if doctor_duration < 0.5:
            raise HTTPException(status_code=400,
                                detail=f"åŒ»ç”Ÿæ³¨å†ŒéŸ³é¢‘æœ‰æ•ˆæ—¶é•¿è¿‡çŸ­ ({doctor_duration:.2f}s)ï¼Œè¯·æä¾›è‡³å°‘ 0.5 ç§’çš„è¯­éŸ³")
        result = _process_transcribe(main_path, doctor_path)

        # ä¿å­˜ç»“æœ
        output_filename = f"transcript_{uuid.uuid4().hex[:8]}_{int(time.time())}.json"
        output_json_path = OUTPUT_DIR / output_filename
        with open(output_json_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        return JSONResponse(content=result)

    except Exception as e:
        logger.error(f"Transcribe å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        for path in [main_path, doctor_path]:
            if path and os.path.exists(path):
                os.unlink(path)

@app.get("/")
def read_root():
    return {
        "message": "æ”¯æŒä¸Šä¼ æ–‡ä»¶å’Œ URL ä¸¤ç§æ–¹å¼ï¼",
        "endpoints": {
            "/asr": [
                "multipart/form-data: audio=æ–‡ä»¶",
                "application/json: {\"audio_url\": \"http://...\"}"
            ],
            "/transcribe": [
                "multipart/form-data: audio=æ–‡ä»¶ & doctor_enroll=æ–‡ä»¶",
                "application/json: {\"audio_url\": \"...\", \"doctor_enroll_url\": \"...\"}"
            ]
        }
    }

# ==============================
# ğŸ å¯åŠ¨
# ==============================
if __name__ == "__main__":
    import uvicorn
    logger.info("Starting ASR server on http://0.0.0.0:8002")
    uvicorn.run(app, host="0.0.0.0", port=8002)